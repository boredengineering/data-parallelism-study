{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42303c78-859f-4aa5-a133-e9846c01d6f5",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2cd73d-6857-4785-b153-0ea44b7890a4",
   "metadata": {},
   "source": [
    "# Workshop Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f532b4-6be6-446d-8ab7-36483dbaabec",
   "metadata": {},
   "source": [
    "Congratulations on all your work thus far in the workshop! You have covered a lot of ground, and now is your chance to demonstrate what you've learned on a novel problem. If you are able to do so successfully you will earn a certificate of competency in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a2659-ce01-4d7c-8707-2b0cd0ca10c0",
   "metadata": {},
   "source": [
    "## Assessment Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0d146-83b3-4bbc-b9c5-d64fc98ddddd",
   "metadata": {},
   "source": [
    "You may or may not have sufficient time to complete this assessment before the allotted time for the workshop today. Please don't worry, if you are unable to complete the assessment before the workshop ends today, you may return to this interactive session at your leisure to try the assessment again.\n",
    "\n",
    "Your work will **not be saved** in between interactive sessions, so it is important if you would like to continue where you leave off between interactive sessions to **save any relevant files to your local machine** before exiting an interactive session and then, via JupyterLab's file menu, drag and drop them back into new interactive sessions, so you can pick up where you left off.\n",
    "\n",
    "You might consider taking a look at the browser tab where you launched this interactive sessions to check how much time you have remaining at the moment before your session times out. Again, you can use that same browser page to re-launch the session at your leisure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c63cc-4695-48d5-9359-18bf164a31b9",
   "metadata": {},
   "source": [
    "## The Assessment Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe60fce-1b2f-4dd7-b019-ea3a977c4379",
   "metadata": {},
   "source": [
    "For the assessment, you will refactor [`assessment.py`](assessment.py), which already runs successfully on a single GPU, to run instead on all 4 GPUs available in this environment, using `DDP`. Open [the file now](assessment.py) and spend several minutes familiarizing yourself with the code, which you'll notice trains on [the CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "**Your goal will be to achieve a validation accuracy of at 0.75 for at least two consecutive epochs in under 300 seconds.**\n",
    "\n",
    "As it stands, `assessment.py` can achieve a validation accuracy of 0.75 for at least two consecutive epochs, however, it takes well over the allotted time to do so. Immediately below is the output from a run of `assessment.py` performed at an earlier time, so that you do not have to take the time to run the script yourself:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6e41c-2467-4af2-b80d-b8180db9ab8d",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch =  1: Cumulative Time = 88.982, Epoch Time = 88.982, Images/sec = 561.0093580791115, Training Accuracy = 0.505, Validation Loss = 1.126, Validation Accuracy = 0.611\n",
    "Epoch =  2: Cumulative Time = 177.335, Epoch Time = 88.353, Images/sec = 565.0089655045808, Training Accuracy = 0.685, Validation Loss = 0.885, Validation Accuracy = 0.708\n",
    "Epoch =  3: Cumulative Time = 264.656, Epoch Time = 87.321, Images/sec = 571.6856192674654, Training Accuracy = 0.747, Validation Loss = 0.604, Validation Accuracy = 0.800\n",
    "Epoch =  4: Cumulative Time = 352.513, Epoch Time = 87.857, Images/sec = 568.1936135215041, Training Accuracy = 0.781, Validation Loss = 0.566, Validation Accuracy = 0.808\n",
    "Early stopping after epoch 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4c913-a210-4178-8c5b-5abe61ac2b1f",
   "metadata": {},
   "source": [
    "However, if you would like to run the script yourself, feel free to execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301057d7-0114-4f5c-a5fc-95c00616d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 assessment.py --batch-size 128 --target-accuracy 0.75 --patience 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d823507-f745-47f5-87be-cc1c2d9a094d",
   "metadata": {},
   "source": [
    "## Guidelines for the Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b379d-6b47-4667-80a2-465385b6a855",
   "metadata": {},
   "source": [
    "For the sake of your own learning, we challenge you to work as much from scratch as you can to solve the assessment. However, to support you in your work, should you need them, a copy of both [the notebook](99_Reference_DDP.ipynb) and [the solution script](lab-2_fashion_mnist_solution.py) from lab 2 have been provided to you to serve as a refresher.\n",
    "\n",
    "You should run the cell below to check your work. Please note that you will need to update [`assessment.py`](assessment.py), at the least to expect additional arguments, before the cell below will run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3833a28-3d3b-4ed3-be7a-b13d8d38ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 assessment.py --node-id 0 --num-gpus 4 --num-nodes 1 --batch-size 128 --target-accuracy 0.75 --patience 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ebee3-9d51-46dd-adcc-b77d04ffd3f8",
   "metadata": {},
   "source": [
    "Once you are able to execute the cell above, observing a `Cumulative Time` of less than 300 seconds, return to the browser tab where you launched this interactive environment and click the **ASSESS** button. Doing so will kick off the assessment harness, which will perform several checks to make sure you have completed the objectives.\n",
    "\n",
    "You will receive a pop-up message indicating whether you have completed the assessment. If you have, you will receive a link to your certificate by way of email. If not, you will receive a message indicating what you may still need to do."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
